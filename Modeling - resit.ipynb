{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d114bfc-a8ee-49fe-82d6-bf04eee303c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import (classification_report, roc_auc_score, confusion_matrix)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import OptunaSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e68773-7b75-4411-bea4-fc65fd423680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (5448, 28)\n",
      "Val size: (4524, 28)\n",
      "Test size: (4077, 28)\n",
      "Positive rates: 0.06167400881057269 0.03713527851458886 0.041206769683590876\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"df_preprocessed_windows.parquet\")\n",
    "\n",
    "#split:\n",
    "train_cycles = [\"B1\", \"B2\"]\n",
    "val_cycles   = [\"A1\"]\n",
    "test_cycles  = [\"A2\"]\n",
    "\n",
    "df_train = df[df[\"cycle_id\"].isin(train_cycles)].copy()\n",
    "df_val   = df[df[\"cycle_id\"].isin(val_cycles)].copy()\n",
    "df_test  = df[df[\"cycle_id\"].isin(test_cycles)].copy()\n",
    "\n",
    "print(\"Train size:\", df_train.shape)\n",
    "print(\"Val size:\", df_val.shape)\n",
    "print(\"Test size:\", df_test.shape)\n",
    "print(\"Positive rates:\",\n",
    "      df_train[\"label\"].mean(),\n",
    "      df_val[\"label\"].mean(),\n",
    "      df_test[\"label\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43083f86-6e5e-48ae-8318-07f9f2c4befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "\n",
    "feature_cols_full = [\n",
    "    c for c in df.columns\n",
    "    if c not in [\"pump_id\", \"cycle_id\", \"end_time\", \"label\"]\n",
    "]\n",
    "\n",
    "feature_cols_reduced = [\n",
    "    \"delta_p_mean\",\n",
    "    \"delta_p_std\",\n",
    "    \"delta_p_trend\",\n",
    "    \"output_mean\",\n",
    "    \"output_std\",\n",
    "    \"output_trend\",\n",
    "    \"active_pressure_fraction\",\n",
    "]\n",
    "\n",
    "FEATURE_SET = \"reduced\"      #  \"full or \"reduced\"----=\n",
    "\n",
    "if FEATURE_SET == \"full\":\n",
    "    feature_cols = feature_cols_full\n",
    "elif FEATURE_SET == \"reduced\":\n",
    "    feature_cols = feature_cols_reduced\n",
    "\n",
    "    \n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "X_val = df_val[feature_cols]\n",
    "y_val = df_val[\"label\"]\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "#==========================use for all models!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "69b64f2f-306a-4476-9b2a-4794d5645a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10, 100]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d3a1356-2081-4c94-93ab-c9f4c76b69ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Logistic Regression parameters:\n",
      "{'clf__C': 100}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator=lr_pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"average_precision\",  # PR-AUC (primary metric)\n",
    "    cv=[(np.arange(len(X_train)), np.arange(len(X_val)))],\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit: training data only\n",
    "grid.fit(\n",
    "    pd.concat([X_train, X_val]),\n",
    "    pd.concat([y_train, y_val])\n",
    ")\n",
    "\n",
    "print(\"\\nBest Logistic Regression parameters:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea1ceb09-c3b8-4200-a649-1631754f3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VALIDATION RESULTS ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.913     0.955      4356\n",
      "           1      0.308     1.000     0.471       168\n",
      "\n",
      "    accuracy                          0.917      4524\n",
      "   macro avg      0.654     0.957     0.713      4524\n",
      "weighted avg      0.974     0.917     0.937      4524\n",
      "\n",
      "ROC-AUC: 0.9804128951856226\n",
      "PR-AUC : 0.6143410485517381\n",
      "Confusion matrix:\n",
      " [[3979  377]\n",
      " [   0  168]]\n"
     ]
    }
   ],
   "source": [
    "y_val_pred  = best_model.predict(X_val)\n",
    "y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"\\n=== VALIDATION RESULTS ===\")\n",
    "print(classification_report(y_val, y_val_pred, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, y_val_proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_val, y_val_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "430e4c01-6099-4c69-9291-2e8210341c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST RESULTS ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.646     0.785      3909\n",
      "           1      0.108     1.000     0.196       168\n",
      "\n",
      "    accuracy                          0.661      4077\n",
      "   macro avg      0.554     0.823     0.490      4077\n",
      "weighted avg      0.963     0.661     0.761      4077\n",
      "\n",
      "ROC-AUC: 0.9192735932950822\n",
      "PR-AUC : 0.1974902728133412\n",
      "Confusion matrix:\n",
      " [[2527 1382]\n",
      " [   0  168]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred  = best_model.predict(X_test)\n",
    "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== TEST RESULTS ===\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, y_test_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "348e7506-807e-45c2-ac11-54e0af5fbf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7, 3))\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_val,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=axes[0],\n",
    "    cbar=False\n",
    ")\n",
    "axes[0].set_title(\"Validation Confusion Matrix (A2)\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_test,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=axes[1],\n",
    "    cbar=False\n",
    ")\n",
    "axes[1].set_title(\"Test Confusion Matrix (B2)\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "917168c6-4ba3-450a-9c0e-6274b2f6c9b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m perm \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_pipe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m perm_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: feature_cols_reduced,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportance_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: perm\u001b[38;5;241m.\u001b[39mimportances_mean,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportance_std\u001b[39m\u001b[38;5;124m\"\u001b[39m: perm\u001b[38;5;241m.\u001b[39mimportances_std\n\u001b[1;32m     14\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportance_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/inspection/_permutation_importance.py:285\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_samples must be <= n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 285\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m \u001b[43m_weights_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m scores \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(\n\u001b[1;32m    288\u001b[0m     delayed(_calculate_permutation_scores)(\n\u001b[1;32m    289\u001b[0m         estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/inspection/_permutation_importance.py:28\u001b[0m, in \u001b[0;36m_weights_scorer\u001b[0;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:288\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:380\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[1;32m    379\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[0;32m--> 380\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_response_method_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:90\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 90\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/_response.py:202\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classifier(estimator):\n\u001b[1;32m    201\u001b[0m     prediction_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, response_method)\n\u001b[0;32m--> 202\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\n\u001b[1;32m    203\u001b[0m     target_type \u001b[38;5;241m=\u001b[39m type_of_target(classes)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/pipeline.py:1216\u001b[0m, in \u001b[0;36mPipeline.classes_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclasses_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The classes labels. Only exist if the last step is a classifier.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "\n",
    "perm = permutation_importance(\n",
    "    lr_pipe,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    scoring=\"f1\",\n",
    "    n_repeats=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols_reduced,\n",
    "    \"importance_mean\": perm.importances_mean,\n",
    "    \"importance_std\": perm.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(\n",
    "    data=perm_df,\n",
    "    x=\"importance_mean\",\n",
    "    y=\"feature\",\n",
    "    color=\"steelblue\"\n",
    ")\n",
    "plt.xlabel(\"Mean decrease in F1-score\", fontsize=11)\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Permutation Importance (Reduced Feature Set, Validation A2)\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782641b-d909-4941-82cd-db2b94ca6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d569050-d0f0-44b0-b40c-957dffbbcb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-07 20:41:33,173] A new study created in memory with name: no-name-6ea6b950-41fc-4b1d-aed3-061b62794e3e\n",
      "[I 2026-01-07 20:41:33,750] Trial 0 finished with value: 0.11329058863524193 and parameters: {'n_estimators': 310, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 0.11329058863524193.\n",
      "[I 2026-01-07 20:41:34,037] Trial 1 finished with value: 0.11291512684321847 and parameters: {'n_estimators': 157, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.11329058863524193.\n",
      "[I 2026-01-07 20:41:34,910] Trial 2 finished with value: 0.12787111425902478 and parameters: {'n_estimators': 499, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.12787111425902478.\n",
      "[I 2026-01-07 20:41:35,437] Trial 3 finished with value: 0.14617147289510618 and parameters: {'n_estimators': 299, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 3 with value: 0.14617147289510618.\n",
      "[I 2026-01-07 20:41:35,852] Trial 4 finished with value: 0.12675892591774987 and parameters: {'n_estimators': 223, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 3 with value: 0.14617147289510618.\n",
      "[I 2026-01-07 20:41:36,211] Trial 5 finished with value: 0.13008120218650487 and parameters: {'n_estimators': 203, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.14617147289510618.\n",
      "[I 2026-01-07 20:41:36,831] Trial 6 finished with value: 0.13541301048762258 and parameters: {'n_estimators': 349, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 3 with value: 0.14617147289510618.\n",
      "[I 2026-01-07 20:41:37,609] Trial 7 finished with value: 0.1432425436227237 and parameters: {'n_estimators': 442, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.14617147289510618.\n",
      "[I 2026-01-07 20:41:38,107] Trial 8 finished with value: 0.12167014942444487 and parameters: {'n_estimators': 266, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 3 with value: 0.14617147289510618.\n",
      "[I 2026-01-07 20:41:38,647] Trial 9 finished with value: 0.15320083918013172 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 9 with value: 0.15320083918013172.\n",
      "[I 2026-01-07 20:41:39,688] Trial 10 finished with value: 0.13505046583939181 and parameters: {'n_estimators': 598, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 9 with value: 0.15320083918013172.\n",
      "[I 2026-01-07 20:41:39,888] Trial 11 finished with value: 0.16210913628219575 and parameters: {'n_estimators': 105, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:40,164] Trial 12 finished with value: 0.13070579077686917 and parameters: {'n_estimators': 143, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:40,372] Trial 13 finished with value: 0.1601364714576731 and parameters: {'n_estimators': 104, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:40,584] Trial 14 finished with value: 0.10671149900852706 and parameters: {'n_estimators': 109, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:40,797] Trial 15 finished with value: 0.15810150119945465 and parameters: {'n_estimators': 102, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:41,170] Trial 16 finished with value: 0.13004505065617367 and parameters: {'n_estimators': 200, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:41,883] Trial 17 finished with value: 0.14168038392310828 and parameters: {'n_estimators': 408, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:42,207] Trial 18 finished with value: 0.09909418804050521 and parameters: {'n_estimators': 176, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:42,663] Trial 19 finished with value: 0.11583702363095526 and parameters: {'n_estimators': 249, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:42,903] Trial 20 finished with value: 0.15447988005787144 and parameters: {'n_estimators': 125, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:43,145] Trial 21 finished with value: 0.14009682346244828 and parameters: {'n_estimators': 116, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:43,482] Trial 22 finished with value: 0.11189263004683253 and parameters: {'n_estimators': 172, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 11 with value: 0.16210913628219575.\n",
      "[I 2026-01-07 20:41:43,703] Trial 23 finished with value: 0.17069032621928967 and parameters: {'n_estimators': 106, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:43,999] Trial 24 finished with value: 0.13334197116149404 and parameters: {'n_estimators': 154, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:44,213] Trial 25 finished with value: 0.16420821497571392 and parameters: {'n_estimators': 100, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:44,670] Trial 26 finished with value: 0.12753608635954744 and parameters: {'n_estimators': 232, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:45,030] Trial 27 finished with value: 0.13504718128173251 and parameters: {'n_estimators': 186, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:45,318] Trial 28 finished with value: 0.12948255990200663 and parameters: {'n_estimators': 145, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:45,955] Trial 29 finished with value: 0.15065665319658347 and parameters: {'n_estimators': 338, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:46,480] Trial 30 finished with value: 0.11708301012785315 and parameters: {'n_estimators': 276, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:46,708] Trial 31 finished with value: 0.1601364714576731 and parameters: {'n_estimators': 104, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:47,004] Trial 32 finished with value: 0.13019171751812048 and parameters: {'n_estimators': 147, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:47,283] Trial 33 finished with value: 0.1421897417481595 and parameters: {'n_estimators': 135, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:47,690] Trial 34 finished with value: 0.12448773710664021 and parameters: {'n_estimators': 209, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:48,027] Trial 35 finished with value: 0.13965343730574703 and parameters: {'n_estimators': 170, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:49,010] Trial 36 finished with value: 0.14077242423633485 and parameters: {'n_estimators': 541, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:49,213] Trial 37 finished with value: 0.12796674339725017 and parameters: {'n_estimators': 102, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:49,981] Trial 38 finished with value: 0.14778856942990698 and parameters: {'n_estimators': 424, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:50,393] Trial 39 finished with value: 0.11651587297247037 and parameters: {'n_estimators': 225, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:50,646] Trial 40 finished with value: 0.13301174853583883 and parameters: {'n_estimators': 130, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:50,853] Trial 41 finished with value: 0.167307878748596 and parameters: {'n_estimators': 106, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:51,153] Trial 42 finished with value: 0.13965343730574703 and parameters: {'n_estimators': 163, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:51,405] Trial 43 finished with value: 0.14004501925392832 and parameters: {'n_estimators': 127, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:51,755] Trial 44 finished with value: 0.1269105645381049 and parameters: {'n_estimators': 191, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:51,966] Trial 45 finished with value: 0.16021105721544934 and parameters: {'n_estimators': 101, 'max_depth': 18, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:52,655] Trial 46 finished with value: 0.1390735548211013 and parameters: {'n_estimators': 387, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:52,949] Trial 47 finished with value: 0.12990504564359787 and parameters: {'n_estimators': 153, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:53,788] Trial 48 finished with value: 0.1507665236119587 and parameters: {'n_estimators': 472, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n",
      "[I 2026-01-07 20:41:54,027] Trial 49 finished with value: 0.14108989826555474 and parameters: {'n_estimators': 125, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 23 with value: 0.17069032621928967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF parameters: {'n_estimators': 106, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#=============================Random forest\n",
    "#=============================\n",
    "\n",
    "def rf_objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 600),   # includes default 100\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 4),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        \"class_weight\": \"balanced_subsample\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    val_proba = rf.predict_proba(X_val)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, val_proba)\n",
    "\n",
    "    return pr_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(rf_objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best RF parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97754f55-47b9-4e20-803a-53c7eb8309db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=15,\n",
       "                       max_features=&#x27;log2&#x27;, min_samples_leaf=4,\n",
       "                       min_samples_split=9, n_estimators=106, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, max_depth=15,\n",
       "                       max_features=&#x27;log2&#x27;, min_samples_leaf=4,\n",
       "                       min_samples_split=9, n_estimators=106, n_jobs=-1,\n",
       "                       random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=15,\n",
       "                       max_features='log2', min_samples_leaf=4,\n",
       "                       min_samples_split=9, n_estimators=106, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final = RandomForestClassifier(\n",
    "    **best_params,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_final.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "339d189c-f6f3-4cdb-a661-16a479fc7522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RANDOM FOREST  VALIDATION ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      4356\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.95      4524\n",
      "   macro avg       0.48      0.49      0.49      4524\n",
      "weighted avg       0.93      0.95      0.94      4524\n",
      "\n",
      "ROC-AUC: 0.7897850255804802\n",
      "PR-AUC : 0.17069032621928967\n",
      "Confusion matrix:\n",
      " [[4294   62]\n",
      " [ 168    0]]\n",
      "\n",
      "=== RANDOM FOREST  TEST ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      3909\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.90      4077\n",
      "   macro avg       0.48      0.47      0.47      4077\n",
      "weighted avg       0.92      0.90      0.91      4077\n",
      "\n",
      "ROC-AUC: 0.5328682892957644\n",
      "PR-AUC : 0.0806334487712269\n",
      "Confusion matrix:\n",
      " [[3673  236]\n",
      " [ 168    0]]\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "val_pred = rf_final.predict(X_val)\n",
    "val_proba = rf_final.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"\\n=== RANDOM FOREST  VALIDATION ===\")\n",
    "print(classification_report(y_val, val_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, val_proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_val, val_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, val_pred))\n",
    "\n",
    "# Test\n",
    "test_pred = rf_final.predict(X_test)\n",
    "test_proba = rf_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== RANDOM FOREST  TEST ===\")\n",
    "print(classification_report(y_test, test_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, test_proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, test_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a68fa-14ca-4304-8848-29eb2a3a5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6e006ec-d3a3-425b-832f-232da22130b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-08 12:49:21,755] A new study created in memory with name: no-name-d01d7d82-0453-42a7-b6f1-0ea1226af29e\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:21,810] Trial 0 finished with value: 0.06169078962929346 and parameters: {'n_estimators': 394, 'max_depth': 4, 'learning_rate': 0.04107441222797902, 'subsample': 0.6554754122056621, 'colsample_bytree': 0.9682779575975535, 'min_child_weight': 10}. Best is trial 0 with value: 0.06169078962929346.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:21,884] Trial 1 finished with value: 0.08508278108973544 and parameters: {'n_estimators': 536, 'max_depth': 7, 'learning_rate': 0.015011520489616521, 'subsample': 0.8266193550814993, 'colsample_bytree': 0.7331330802431674, 'min_child_weight': 8}. Best is trial 1 with value: 0.08508278108973544.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:21,934] Trial 2 finished with value: 0.0563052812225735 and parameters: {'n_estimators': 426, 'max_depth': 2, 'learning_rate': 0.02406052231878621, 'subsample': 0.9551847792808074, 'colsample_bytree': 0.9649802021969043, 'min_child_weight': 9}. Best is trial 1 with value: 0.08508278108973544.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:21,963] Trial 3 finished with value: 0.057229550961454094 and parameters: {'n_estimators': 109, 'max_depth': 9, 'learning_rate': 0.15659170016823792, 'subsample': 0.7235171420691652, 'colsample_bytree': 0.8457748165212579, 'min_child_weight': 5}. Best is trial 1 with value: 0.08508278108973544.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:21,996] Trial 4 finished with value: 0.05992588737597812 and parameters: {'n_estimators': 218, 'max_depth': 3, 'learning_rate': 0.13895542158803725, 'subsample': 0.8330663409897453, 'colsample_bytree': 0.8770774845735823, 'min_child_weight': 7}. Best is trial 1 with value: 0.08508278108973544.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,037] Trial 5 finished with value: 0.0681039834439445 and parameters: {'n_estimators': 497, 'max_depth': 3, 'learning_rate': 0.0680078450028224, 'subsample': 0.9917197986423256, 'colsample_bytree': 0.9997566316013108, 'min_child_weight': 3}. Best is trial 1 with value: 0.08508278108973544.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,076] Trial 6 finished with value: 0.05975924320970618 and parameters: {'n_estimators': 267, 'max_depth': 5, 'learning_rate': 0.07886679011885712, 'subsample': 0.9948210273899845, 'colsample_bytree': 0.8128984028337837, 'min_child_weight': 7}. Best is trial 1 with value: 0.08508278108973544.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,142] Trial 7 finished with value: 0.06516746039916317 and parameters: {'n_estimators': 105, 'max_depth': 8, 'learning_rate': 0.024882963641305694, 'subsample': 0.8166388016936387, 'colsample_bytree': 0.9753034844317108, 'min_child_weight': 2}. Best is trial 1 with value: 0.08508278108973544.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,211] Trial 8 finished with value: 0.10580605725646967 and parameters: {'n_estimators': 573, 'max_depth': 5, 'learning_rate': 0.02909553364855248, 'subsample': 0.9745347375928242, 'colsample_bytree': 0.6026083283558262, 'min_child_weight': 10}. Best is trial 8 with value: 0.10580605725646967.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,302] Trial 9 finished with value: 0.053454730550264444 and parameters: {'n_estimators': 130, 'max_depth': 3, 'learning_rate': 0.01532953392983849, 'subsample': 0.708144675111598, 'colsample_bytree': 0.8701029944834269, 'min_child_weight': 9}. Best is trial 8 with value: 0.10580605725646967.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,335] Trial 10 finished with value: 0.049746208272903915 and parameters: {'n_estimators': 599, 'max_depth': 6, 'learning_rate': 0.28202014818203014, 'subsample': 0.9153634323869948, 'colsample_bytree': 0.6052761310643893, 'min_child_weight': 5}. Best is trial 8 with value: 0.10580605725646967.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,461] Trial 11 finished with value: 0.11182945725108867 and parameters: {'n_estimators': 591, 'max_depth': 7, 'learning_rate': 0.010208393703034004, 'subsample': 0.8866467902995125, 'colsample_bytree': 0.6434451658118235, 'min_child_weight': 8}. Best is trial 11 with value: 0.11182945725108867.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,584] Trial 12 finished with value: 0.11004667283062342 and parameters: {'n_estimators': 586, 'max_depth': 10, 'learning_rate': 0.010121128921812887, 'subsample': 0.8913296963374446, 'colsample_bytree': 0.6026393412709424, 'min_child_weight': 10}. Best is trial 11 with value: 0.11182945725108867.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,715] Trial 13 finished with value: 0.108732356563221 and parameters: {'n_estimators': 479, 'max_depth': 10, 'learning_rate': 0.010154426874720452, 'subsample': 0.8891376661388607, 'colsample_bytree': 0.685376883057353, 'min_child_weight': 7}. Best is trial 11 with value: 0.11182945725108867.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,823] Trial 14 finished with value: 0.09775331151928746 and parameters: {'n_estimators': 323, 'max_depth': 10, 'learning_rate': 0.011126536124876877, 'subsample': 0.8738155108095199, 'colsample_bytree': 0.6700342971560415, 'min_child_weight': 8}. Best is trial 11 with value: 0.11182945725108867.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,893] Trial 15 finished with value: 0.06923405123696169 and parameters: {'n_estimators': 467, 'max_depth': 8, 'learning_rate': 0.01860620923901086, 'subsample': 0.7385564980333235, 'colsample_bytree': 0.7372052738711873, 'min_child_weight': 10}. Best is trial 11 with value: 0.11182945725108867.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:22,955] Trial 16 finished with value: 0.11206530735577334 and parameters: {'n_estimators': 544, 'max_depth': 7, 'learning_rate': 0.042038984118653165, 'subsample': 0.9264275057047838, 'colsample_bytree': 0.6587804851608838, 'min_child_weight': 6}. Best is trial 16 with value: 0.11206530735577334.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,005] Trial 17 finished with value: 0.11148565025633035 and parameters: {'n_estimators': 529, 'max_depth': 7, 'learning_rate': 0.04517604549107519, 'subsample': 0.9322423571764091, 'colsample_bytree': 0.6776623973930147, 'min_child_weight': 4}. Best is trial 16 with value: 0.11206530735577334.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,049] Trial 18 finished with value: 0.05929125879512527 and parameters: {'n_estimators': 376, 'max_depth': 6, 'learning_rate': 0.09898864203174429, 'subsample': 0.7862445727158065, 'colsample_bytree': 0.7349128894148762, 'min_child_weight': 6}. Best is trial 16 with value: 0.11206530735577334.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,101] Trial 19 finished with value: 0.10951469818534107 and parameters: {'n_estimators': 437, 'max_depth': 8, 'learning_rate': 0.03895020076339946, 'subsample': 0.606708638899448, 'colsample_bytree': 0.6553369093868551, 'min_child_weight': 1}. Best is trial 16 with value: 0.11206530735577334.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,133] Trial 20 finished with value: 0.057229550961454094 and parameters: {'n_estimators': 537, 'max_depth': 7, 'learning_rate': 0.28902327765210484, 'subsample': 0.8608836583640906, 'colsample_bytree': 0.791813762095907, 'min_child_weight': 6}. Best is trial 16 with value: 0.11206530735577334.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,196] Trial 21 finished with value: 0.11687941771319023 and parameters: {'n_estimators': 529, 'max_depth': 7, 'learning_rate': 0.04169027496535431, 'subsample': 0.948214529797072, 'colsample_bytree': 0.6531198402345081, 'min_child_weight': 4}. Best is trial 21 with value: 0.11687941771319023.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,247] Trial 22 finished with value: 0.11216686000459902 and parameters: {'n_estimators': 551, 'max_depth': 7, 'learning_rate': 0.05967852520887813, 'subsample': 0.9320595244739955, 'colsample_bytree': 0.6442404668969941, 'min_child_weight': 4}. Best is trial 21 with value: 0.11687941771319023.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,297] Trial 23 finished with value: 0.11944083386118844 and parameters: {'n_estimators': 514, 'max_depth': 5, 'learning_rate': 0.060314195736363284, 'subsample': 0.9376499948473335, 'colsample_bytree': 0.7070809409806248, 'min_child_weight': 4}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,351] Trial 24 finished with value: 0.11757688814305725 and parameters: {'n_estimators': 495, 'max_depth': 5, 'learning_rate': 0.06058556051752643, 'subsample': 0.9517532398390762, 'colsample_bytree': 0.7038321570398732, 'min_child_weight': 3}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,391] Trial 25 finished with value: 0.07714306788043768 and parameters: {'n_estimators': 494, 'max_depth': 5, 'learning_rate': 0.08383455105397279, 'subsample': 0.9554512231449059, 'colsample_bytree': 0.7123330063411815, 'min_child_weight': 3}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,429] Trial 26 finished with value: 0.06544084740231067 and parameters: {'n_estimators': 438, 'max_depth': 4, 'learning_rate': 0.12300315017359593, 'subsample': 0.9644974009754053, 'colsample_bytree': 0.7719416712445958, 'min_child_weight': 3}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,481] Trial 27 finished with value: 0.11927952822666218 and parameters: {'n_estimators': 315, 'max_depth': 6, 'learning_rate': 0.05254860707719457, 'subsample': 0.763995662334403, 'colsample_bytree': 0.7076667975594559, 'min_child_weight': 4}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,522] Trial 28 finished with value: 0.05360626238478713 and parameters: {'n_estimators': 303, 'max_depth': 6, 'learning_rate': 0.18454254717392884, 'subsample': 0.7542253715112333, 'colsample_bytree': 0.7053649479902089, 'min_child_weight': 1}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,584] Trial 29 finished with value: 0.07303682712570712 and parameters: {'n_estimators': 374, 'max_depth': 4, 'learning_rate': 0.03378043623323574, 'subsample': 0.6871531936949489, 'colsample_bytree': 0.7656391138023094, 'min_child_weight': 2}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,645] Trial 30 finished with value: 0.11618854881119829 and parameters: {'n_estimators': 203, 'max_depth': 5, 'learning_rate': 0.05901372786913723, 'subsample': 0.7722369172012986, 'colsample_bytree': 0.7071791736665839, 'min_child_weight': 2}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,712] Trial 31 finished with value: 0.1171547194878144 and parameters: {'n_estimators': 413, 'max_depth': 6, 'learning_rate': 0.049931702895981964, 'subsample': 0.8551707897135591, 'colsample_bytree': 0.6291003366062229, 'min_child_weight': 4}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,775] Trial 32 finished with value: 0.07333102657749098 and parameters: {'n_estimators': 401, 'max_depth': 6, 'learning_rate': 0.05111416667236244, 'subsample': 0.8431325523113766, 'colsample_bytree': 0.7526577738734352, 'min_child_weight': 4}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,822] Trial 33 finished with value: 0.06375907436028225 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.10062983822417171, 'subsample': 0.7989723140836797, 'colsample_bytree': 0.6290309639909609, 'min_child_weight': 5}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,866] Trial 34 finished with value: 0.06998087297382463 and parameters: {'n_estimators': 451, 'max_depth': 4, 'learning_rate': 0.07250676039554523, 'subsample': 0.8567526461294894, 'colsample_bytree': 0.6877231219953622, 'min_child_weight': 3}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,909] Trial 35 finished with value: 0.07317432999222295 and parameters: {'n_estimators': 406, 'max_depth': 6, 'learning_rate': 0.05111582120326573, 'subsample': 0.9055123888314571, 'colsample_bytree': 0.8173769363805151, 'min_child_weight': 4}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:23,972] Trial 36 finished with value: 0.08622201446322306 and parameters: {'n_estimators': 287, 'max_depth': 5, 'learning_rate': 0.03133152385895488, 'subsample': 0.8213506075636678, 'colsample_bytree': 0.7213195701575686, 'min_child_weight': 5}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,021] Trial 37 finished with value: 0.06659966450915375 and parameters: {'n_estimators': 233, 'max_depth': 4, 'learning_rate': 0.06454731438326185, 'subsample': 0.7678057121105368, 'colsample_bytree': 0.692509419435839, 'min_child_weight': 3}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,063] Trial 38 finished with value: 0.05150365146757255 and parameters: {'n_estimators': 326, 'max_depth': 2, 'learning_rate': 0.09606719736071041, 'subsample': 0.6636350592861465, 'colsample_bytree': 0.6306879960046815, 'min_child_weight': 2}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,129] Trial 39 finished with value: 0.0850540564669204 and parameters: {'n_estimators': 513, 'max_depth': 6, 'learning_rate': 0.025679958957681732, 'subsample': 0.999752299535555, 'colsample_bytree': 0.7879531827563995, 'min_child_weight': 5}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,179] Trial 40 finished with value: 0.06813626935847969 and parameters: {'n_estimators': 413, 'max_depth': 3, 'learning_rate': 0.036522436024596136, 'subsample': 0.8052417478566031, 'colsample_bytree': 0.8296780121565597, 'min_child_weight': 3}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,226] Trial 41 finished with value: 0.11910205455540587 and parameters: {'n_estimators': 503, 'max_depth': 5, 'learning_rate': 0.04906968107305077, 'subsample': 0.942843266594384, 'colsample_bytree': 0.6248779333125205, 'min_child_weight': 4}. Best is trial 23 with value: 0.11944083386118844.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,281] Trial 42 finished with value: 0.11998040148071287 and parameters: {'n_estimators': 466, 'max_depth': 5, 'learning_rate': 0.049800048076586716, 'subsample': 0.9722756686285132, 'colsample_bytree': 0.6225521602943023, 'min_child_weight': 4}. Best is trial 42 with value: 0.11998040148071287.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,321] Trial 43 finished with value: 0.07716401368362727 and parameters: {'n_estimators': 505, 'max_depth': 5, 'learning_rate': 0.07750600207445024, 'subsample': 0.9747896937620022, 'colsample_bytree': 0.6136273231570721, 'min_child_weight': 4}. Best is trial 42 with value: 0.11998040148071287.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,368] Trial 44 finished with value: 0.06477126896789008 and parameters: {'n_estimators': 570, 'max_depth': 5, 'learning_rate': 0.057682796681717295, 'subsample': 0.980221251701638, 'colsample_bytree': 0.746514553679875, 'min_child_weight': 5}. Best is trial 42 with value: 0.11998040148071287.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,420] Trial 45 finished with value: 0.06865100500248937 and parameters: {'n_estimators': 474, 'max_depth': 4, 'learning_rate': 0.047655381756610445, 'subsample': 0.9435988475321802, 'colsample_bytree': 0.9141076726217856, 'min_child_weight': 3}. Best is trial 42 with value: 0.11998040148071287.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,469] Trial 46 finished with value: 0.07313339740487473 and parameters: {'n_estimators': 456, 'max_depth': 5, 'learning_rate': 0.06583232096607361, 'subsample': 0.9799602632901779, 'colsample_bytree': 0.6957571192289084, 'min_child_weight': 2}. Best is trial 42 with value: 0.11998040148071287.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,514] Trial 47 finished with value: 0.0678884425235551 and parameters: {'n_estimators': 486, 'max_depth': 4, 'learning_rate': 0.08575017162783427, 'subsample': 0.9096712766279211, 'colsample_bytree': 0.7257670292157673, 'min_child_weight': 5}. Best is trial 42 with value: 0.11998040148071287.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,581] Trial 48 finished with value: 0.07950433507759949 and parameters: {'n_estimators': 261, 'max_depth': 3, 'learning_rate': 0.029259378190533262, 'subsample': 0.9658973061900706, 'colsample_bytree': 0.6705070316900267, 'min_child_weight': 4}. Best is trial 42 with value: 0.11998040148071287.\n",
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2026-01-08 12:49:24,668] Trial 49 finished with value: 0.11123684343302018 and parameters: {'n_estimators': 514, 'max_depth': 5, 'learning_rate': 0.020135029537590277, 'subsample': 0.920034790819499, 'colsample_bytree': 0.6128415766670742, 'min_child_weight': 3}. Best is trial 42 with value: 0.11998040148071287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost parameters:\n",
      "{'n_estimators': 466, 'max_depth': 5, 'learning_rate': 0.049800048076586716, 'subsample': 0.9722756686285132, 'colsample_bytree': 0.6225521602943023, 'min_child_weight': 4}\n",
      "Best validation PR-AUC: 0.11998040148071287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#=====================\n",
    "#=====================XGBoost\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 600),   # default = 100\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),            # default = 6\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),  # default = 0.3\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),       # default = 1.0\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0), # default = 1.0\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10), # default = 1\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "\n",
    "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, y_val_proba)\n",
    "\n",
    "    return pr_auc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best XGBoost parameters:\")\n",
    "print(study.best_params)\n",
    "print(\"Best validation PR-AUC:\", study.best_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32761dd1-c551-4f3d-8c7e-0b2d7c7a6dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teunlangenhuijsen/thesis_env/lib/python3.9/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/IPython/core/formatters.py:974\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    971\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/base.py:469\u001b[0m, in \u001b[0;36mBaseEstimator._repr_mimebundle_\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m output \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)}\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiagram\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 469\u001b[0m     output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mestimator_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/_estimator_html_repr.py:387\u001b[0m, in \u001b[0;36mestimator_html_repr\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m         \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m         status_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<span>Fitted</span>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         is_fitted_css_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[1;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/base.py:463\u001b[0m, in \u001b[0;36mBaseEstimator._repr_html_inner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr_html_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    459\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is returned by the @property `_repr_html_` to make\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    `hasattr(estimator, \"_repr_html_\") return `True` or `False` depending\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m    on `get_config()[\"display\"]`.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/_estimator_html_repr.py:387\u001b[0m, in \u001b[0;36mestimator_html_repr\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m         \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m         status_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<span>Fitted</span>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         is_fitted_css_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/utils/_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/thesis_env/lib/python3.9/site-packages/sklearn/base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[1;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6225521602943023, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', feature_types=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.049800048076586716,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=466, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "xgb_final = XGBClassifier(\n",
    "    **best_params,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_final.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False,\n",
    "    early_stopping_rounds=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7989dc77-2aa9-4229-a3c4-de9bd03da35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBOOST  VALIDATION ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      4356\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.95      4524\n",
      "   macro avg       0.48      0.49      0.49      4524\n",
      "weighted avg       0.93      0.95      0.94      4524\n",
      "\n",
      "ROC-AUC: 0.6878846637369365\n",
      "PR-AUC : 0.11998040148071287\n",
      "Confusion matrix:\n",
      " [[4294   62]\n",
      " [ 168    0]]\n",
      "\n",
      "=== XGBOOST  TEST ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      3909\n",
      "           1       0.00      0.00      0.00       168\n",
      "\n",
      "    accuracy                           0.90      4077\n",
      "   macro avg       0.48      0.47      0.47      4077\n",
      "weighted avg       0.92      0.90      0.91      4077\n",
      "\n",
      "ROC-AUC: 0.38597132380708743\n",
      "PR-AUC : 0.061307420748128824\n",
      "Confusion matrix:\n",
      " [[3680  229]\n",
      " [ 168    0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#val\n",
    "y_val_pred  = xgb_final.predict(X_val)\n",
    "y_val_proba = xgb_final.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"\\n=== XGBOOST  VALIDATION ===\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, y_val_proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_val, y_val_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "# \n",
    "y_test_pred  = xgb_final.predict(X_test)\n",
    "y_test_proba = xgb_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== XGBOOST  TEST ===\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba))\n",
    "print(\"PR-AUC :\", average_precision_score(y_test, y_test_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e6c0f-036f-41de-a44b-7f41aee106cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8a47966-0e63-4fd7-a053-4b5c6bf63ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best OC-SVM hyperparameters:\n",
      "{'kernel': 'poly', 'nu': 0.01, 'gamma': 'scale'}\n",
      "Best validation PR-AUC: 0.07121150697579051\n",
      "\n",
      "=== AUC ===\n",
      "VAL  ROC-AUC: 0.7671848353666536\n",
      "VAL  PR-AUC : 0.07121150697579051\n",
      "TEST ROC-AUC: 0.9143079462534567\n",
      "TEST PR-AUC : 0.18463739171405164\n",
      "\n",
      "Selected threshold (validation): 0.1786079539967118\n",
      "Best validation F1: 0.15112540192926044\n",
      "\n",
      "=== THRESHOLDED PERFORMANCE ===\n",
      "Validation:\n",
      "(0.08303886925795052, 0.8392857142857143, 0.15112540192926044, None)\n",
      "Confusion matrix:\n",
      " [[2799 1557]\n",
      " [  27  141]]\n",
      "\n",
      "Test:\n",
      "(0.1320754716981132, 1.0, 0.23333333333333334, None)\n",
      "Confusion matrix:\n",
      " [[2805 1104]\n",
      " [   0  168]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =================\n",
    "# =================OneClass-SVM\n",
    "\n",
    "# train\n",
    "X_train_h = X_train[y_train == 0].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_h_scaled = scaler.fit_transform(X_train_h)\n",
    "X_val_scaled     = scaler.transform(X_val)\n",
    "X_test_scaled    = scaler.transform(X_test)\n",
    "\n",
    "# hyperparameters\n",
    "param_grid = {\n",
    "    \"kernel\": [\"rbf\", \"poly\"],\n",
    "    \"nu\": [0.01, 0.05, 0.10, 0.20, 0.50],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "best_pr_auc = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for kernel, nu, gamma in itertools.product(\n",
    "    param_grid[\"kernel\"],\n",
    "    param_grid[\"nu\"],\n",
    "    param_grid[\"gamma\"]\n",
    "):\n",
    "    model = OneClassSVM(kernel=kernel, nu=nu, gamma=gamma)\n",
    "    model.fit(X_train_h_scaled)\n",
    "\n",
    "    val_scores = -model.decision_function(X_val_scaled)\n",
    "    pr_auc = average_precision_score(y_val, val_scores)\n",
    "\n",
    "    if pr_auc > best_pr_auc:\n",
    "        best_pr_auc = pr_auc\n",
    "        best_params = {\n",
    "            \"kernel\": kernel,\n",
    "            \"nu\": nu,\n",
    "            \"gamma\": gamma\n",
    "        }\n",
    "\n",
    "print(\"\\nBest OC-SVM hyperparameters:\")\n",
    "print(best_params)\n",
    "print(\"Best validation PR-AUC:\", best_pr_auc)\n",
    "\n",
    "# fit\n",
    "best_ocsvm = OneClassSVM(**best_params)\n",
    "best_ocsvm.fit(X_train_h_scaled)\n",
    "\n",
    "val_scores  = -best_ocsvm.decision_function(X_val_scaled)\n",
    "test_scores = -best_ocsvm.decision_function(X_test_scaled)\n",
    "\n",
    "# auc (no treshold\n",
    "print(\"\\n=== AUC ===\")\n",
    "print(\"VAL  ROC-AUC:\", roc_auc_score(y_val, val_scores))\n",
    "print(\"VAL  PR-AUC :\", average_precision_score(y_val, val_scores))\n",
    "print(\"TEST ROC-AUC:\", roc_auc_score(y_test, test_scores))\n",
    "print(\"TEST PR-AUC :\", average_precision_score(y_test, test_scores))\n",
    "\n",
    "# treshold selection\n",
    "thresholds = np.linspace(\n",
    "    np.percentile(val_scores, 1),\n",
    "    np.percentile(val_scores, 99),\n",
    "    200\n",
    ")\n",
    "\n",
    "best_f1 = -1\n",
    "best_threshold = None\n",
    "\n",
    "for t in thresholds:\n",
    "    val_pred = (val_scores >= t).astype(int)\n",
    "    _, _, f1, _ = precision_recall_fscore_support(\n",
    "        y_val, val_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(\"\\nSelected threshold (validation):\", best_threshold)\n",
    "print(\"Best validation F1:\", best_f1)\n",
    "\n",
    "# performance\n",
    "val_pred  = (val_scores  >= best_threshold).astype(int)\n",
    "test_pred = (test_scores >= best_threshold).astype(int)\n",
    "\n",
    "print(\"\\n=== THRESHOLDED PERFORMANCE ===\")\n",
    "print(\"Validation:\")\n",
    "print(precision_recall_fscore_support(\n",
    "    y_val, val_pred, average=\"binary\", zero_division=0\n",
    "))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, val_pred))\n",
    "\n",
    "print(\"\\nTest:\")\n",
    "print(precision_recall_fscore_support(\n",
    "    y_test, test_pred, average=\"binary\", zero_division=0\n",
    "))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262538a7-d99f-4a7a-af4b-3664b7638cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7965fc9c-ca10-4643-b1a4-68780ca8e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Isolation Forest hyperparameters:\n",
      "{'n_estimators': 100, 'max_samples': 0.8, 'contamination': 0.01}\n",
      "Best validation PR-AUC: 0.03711726885557601\n",
      "\n",
      "=== AUC ===\n",
      "VAL  ROC-AUC: 0.5467240041103677\n",
      "VAL  PR-AUC : 0.03711726885557601\n",
      "TEST ROC-AUC: 0.6998935606475898\n",
      "TEST PR-AUC : 0.06121854802336039\n",
      "\n",
      "Selected threshold (validation): -0.07978712476539365\n",
      "Best validation F1: 0.0829805249788315\n",
      "\n",
      "=== THRESHOLDED PERFORMANCE ===\n",
      "\n",
      "Validation:\n",
      "(0.044667274384685506, 0.5833333333333334, 0.0829805249788315, None)\n",
      "Confusion matrix:\n",
      " [[2260 2096]\n",
      " [  70   98]]\n",
      "\n",
      "Test:\n",
      "(0.04566458276705627, 1.0, 0.08734078502729399, None)\n",
      "Confusion matrix:\n",
      " [[ 398 3511]\n",
      " [   0  168]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =================\n",
    "# =================isolation forest\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# train\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "\n",
    "# hyperparameter\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"max_samples\": [0.6, 0.8, 1.0],\n",
    "    \"contamination\": [0.01, 0.02, 0.05, 0.10],\n",
    "}\n",
    "\n",
    "best_pr_auc = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for n_estimators in param_grid[\"n_estimators\"]:\n",
    "    for max_samples in param_grid[\"max_samples\"]:\n",
    "        for contamination in param_grid[\"contamination\"]:\n",
    "            model = IsolationForest(\n",
    "                n_estimators=n_estimators,\n",
    "                max_samples=max_samples,\n",
    "                contamination=contamination,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            model.fit(X_train_normal)\n",
    "\n",
    "            val_scores = -model.decision_function(X_val)\n",
    "            pr_auc = average_precision_score(y_val, val_scores)\n",
    "\n",
    "            if pr_auc > best_pr_auc:\n",
    "                best_pr_auc = pr_auc\n",
    "                best_params = {\n",
    "                    \"n_estimators\": n_estimators,\n",
    "                    \"max_samples\": max_samples,\n",
    "                    \"contamination\": contamination\n",
    "                }\n",
    "                best_model = model\n",
    "\n",
    "print(\"\\nBest Isolation Forest hyperparameters:\")\n",
    "print(best_params)\n",
    "print(\"Best validation PR-AUC:\", best_pr_auc)\n",
    "\n",
    "# anomaly scores\n",
    "val_scores  = -best_model.decision_function(X_val)\n",
    "test_scores = -best_model.decision_function(X_test)\n",
    "\n",
    "print(\"\\n=== AUC ===\")\n",
    "print(\"VAL  ROC-AUC:\", roc_auc_score(y_val, val_scores))\n",
    "print(\"VAL  PR-AUC :\", average_precision_score(y_val, val_scores))\n",
    "print(\"TEST ROC-AUC:\", roc_auc_score(y_test, test_scores))\n",
    "print(\"TEST PR-AUC :\", average_precision_score(y_test, test_scores))\n",
    "\n",
    "# treshold selection\n",
    "thresholds = np.percentile(val_scores, np.linspace(50, 99.9, 300))\n",
    "\n",
    "best_f1 = -1\n",
    "best_threshold = None\n",
    "\n",
    "for t in thresholds:\n",
    "    val_pred = (val_scores >= t).astype(int)\n",
    "    _, _, f1, _ = precision_recall_fscore_support(\n",
    "        y_val, val_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = t\n",
    "\n",
    "print(\"\\nSelected threshold (validation):\", best_threshold)\n",
    "print(\"Best validation F1:\", best_f1)\n",
    "\n",
    "# performance\n",
    "val_pred  = (val_scores  >= best_threshold).astype(int)\n",
    "test_pred = (test_scores >= best_threshold).astype(int)\n",
    "\n",
    "print(\"\\n=== THRESHOLDED PERFORMANCE ===\")\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "print(precision_recall_fscore_support(\n",
    "    y_val, val_pred, average=\"binary\", zero_division=0\n",
    "))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, val_pred))\n",
    "\n",
    "print(\"\\nTest:\")\n",
    "print(precision_recall_fscore_support(\n",
    "    y_test, test_pred, average=\"binary\", zero_division=0\n",
    "))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis_env)",
   "language": "python",
   "name": "thesis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
